"""
Below is Just the Code used in the assignment. 
Access the Assignment from- https://colab.research.google.com/drive/1rHvtre591Zf451JQhe7_ZLd_8hjFP-V7
"""

# -*- coding: utf-8 -*-
"""Writing_Assignment_Machine_minds_Group2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rHvtre591Zf451JQhe7_ZLd_8hjFP-V7

**Team members**: Chaitanya(23110052), Keerthan(2330068), Avinash(23110123),  Dinesh(23110168), Praneeth(23110226)

**Team name**: Machine minds

Datasets Collected from-

https://censusindia.gov.in/census.website/data/census-tables

https://mospi.gov.in/sites/default/files/reports_and_publication/statistical_publication/social_statistics/WM16Chapter3.pdf

https://www.data.gov.in/resource/stateut-wise-details-rural-literacy-rate-india-2019-20-2023-24

https://censusindia.gov.in/nada/index.php/catalog/43333/study-description

https://secc.gov.in/getOtherCategoryIncomeSlabNationalReport.htm

https://cpcb.nic.in/displaypdf.php?id=bWFudWFsLW1vbml0b3JpbmcvQnVsbGV0aW5fQVFJX05BTVBfT2N0MjAxNS5wZGY=

https://eacpm.gov.in/wp-content/uploads/2024/09/State-GDP-Working-Paper_Final.pdf

Datasets Used-
https://drive.google.com/drive/folders/19_LWyxqyj_4fUFyB3aXkuGPGkGNxffoD?usp=sharing

INTRODUCTION:

India is growing and changing in many ways, and this growth depends on many important factors. In this analysis, we look at key aspects like literacy, population, per capita income, fertility rate, and PM 2.5 air pollution levels in different states. These factors are all connected and help us understand how people’s lives are improving, where problems still exist, and how things are changing over time. By studying these trends, we can get a better idea of how India is developing and what challenges need to be addressed for a better future.
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import folium
import json
import branca.colormap as cm

with open("/content/drive/MyDrive/india_state (2).geojson", "r") as f:
    india_geo = json.load(f)

pm_df = pd.read_csv("/content/pm_2.5 - Sheet1.csv")
pm_df.rename(columns={'Region/State name': 'State'}, inplace=True)
pm_df['State'] = pm_df['State'].str.strip().str.lower()
pm_df['2020'] = pm_df['Pm 2.5'].astype(str).str.extract(r'([\d.]+)').astype(float)

name_corrections = {
    'andaman and nicobar islands': 'andaman and nicobar',
    'nct of delhi': 'delhi',
    'dadra and nagar haveli and daman and diu': 'daman and diu',
    'jammu & kashmir': 'jammu and kashmir',
    'odisha': 'orissa',
    'pondicherry': 'puducherry',
    'uttarakhand': 'uttaranchal',
}

pm_df["State"] = pm_df["State"].replace(name_corrections)

for feature in india_geo["features"]:
    feature["id"] = feature["properties"]["NAME_1"].strip().lower()

geo_states = [feature["id"] for feature in india_geo["features"]]
pm_df = pm_df[pm_df["State"].isin(geo_states)]

m = folium.Map(location=[22.5, 80], zoom_start=5, tiles="CartoDB positron")

min_val = pm_df["2020"].min()
max_val = pm_df["2020"].max()
colormap = cm.linear.RdYlGn_11.scale(min_val, max_val).to_step(n=10)

folium.Choropleth(
    geo_data=india_geo,
    name="PM2.5 Choropleth",
    data=pm_df,
    columns=["State", "2020"],
    key_on="feature.id",
    fill_color="RdYlGn_r",
    fill_opacity=0.9,
    line_opacity=0.8,
    line_color="black",
    legend_name="PM2.5 Levels in 2020 (µg/m³)",
    highlight=True
).add_to(m)

folium.GeoJson(
    india_geo,
    name="State Labels",
    style_function=lambda feature: {
        "fillColor": "transparent",
        "color": "black",
        "weight": 1,
        "dashArray": "3, 3"
    },
    tooltip=folium.GeoJsonTooltip(fields=["NAME_1"], aliases=["State:"])
).add_to(m)

m

"""Key Observations:

 The heatmap clearly shows Delhi as the most polluted state, followed by the surrounding northern states. Additionally, regions near the Tropic of Cancer—such as parts of Madhya Pradesh, Chhattisgarh, and Jharkhand—appear redder, indicating higher PM2.5 levels. In contrast, southern and northeastern states are mostly green, signifying cleaner air.

 Delhi stands out as the most polluted, followed closely by its northern neighbors—largely due to dense population, vehicular emissions, industrial activity, and seasonal stubble burning in Punjab and Haryana. The region’s landlocked geography and winter conditions, including fog and low wind speeds, further trap pollutants. Central states along the Tropic of Cancer—such as Madhya Pradesh, Chhattisgarh, and Jharkhand—also exhibit high pollution levels, driven by coal-based industries, mining, deforestation, and a dry climate that limits natural air purification. In contrast, southern and northeastern states enjoy significantly cleaner air, thanks to denser forest cover, higher rainfall, lower population density, and comparatively less industrialization.
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

literacy_df = pd.read_csv('/content/literacy_rates_from_19_to_25.csv')

literacy_df.columns = literacy_df.columns.str.strip()

literacy_years = ['2019-20', '2020-21', '2021-22', '2022-23', '2023-24']
literacy_df['State/UT'] = literacy_df['State/UT'].str.strip().str.lower()
literacy_df['Avg_Literacy'] = literacy_df[literacy_years].mean(axis=1)

pm_df.rename(columns={'State': 'State/UT'}, inplace=True)

merged = pd.merge(
    literacy_df[['State/UT', 'Avg_Literacy']],
    pm_df[['State/UT', '2020']],
    on='State/UT'
)

merged.rename(columns={'2020': 'Pm 2.5'}, inplace=True)

median_lit = merged['Avg_Literacy'].median()
merged['Literacy_Group'] = merged['Avg_Literacy'].apply(
    lambda x: 'High Literacy' if x >= median_lit else 'Low Literacy'
)

merged_sorted = merged.sort_values(by='Pm 2.5', ascending=True)

sns.set(style='whitegrid')

plt.figure(figsize=(10, 7))
sns.boxplot(
    data=merged_sorted,
    x='Literacy_Group',
    y='Pm 2.5',
    hue='Literacy_Group',
    palette='Set2',
    showfliers=False
)

sns.stripplot(
    data=merged_sorted,
    x='Literacy_Group',
    y='Pm 2.5',
    color='black',
    alpha=0.6,
    jitter=0.2
)

plt.yticks(range(0, int(merged_sorted['Pm 2.5'].max()) + 10, 10))
plt.grid(True, axis='y', linestyle='--', linewidth=0.5)

plt.title("PM2.5 Levels in High vs Low Literacy States", fontsize=14, weight='bold')
plt.xlabel("Literacy Group", fontsize=12)
plt.ylabel("PM2.5 (μg/m³)", fontsize=12)
plt.tight_layout()
plt.show()

print(merged.groupby('Literacy_Group')['Pm 2.5'].mean())

from scipy.stats import ttest_ind
high_lit_pm25 = merged[merged['Literacy_Group'] == 'High Literacy']['Pm 2.5']
low_lit_pm25 = merged[merged['Literacy_Group'] == 'Low Literacy']['Pm 2.5']
t_stat, p_val = ttest_ind(high_lit_pm25, low_lit_pm25, equal_var=False)
print(f"T-statistic: {t_stat}")
print(f"P-value: {p_val}")

"""##  Hypothesis Test: PM2.5 Levels in High vs. Low Literacy States

---

###  Hypothesis Statement

We aim to examine whether the average PM2.5 concentration (fine particulate matter) differs between Indian states with high literacy rates and those with low literacy rates.

- *Null Hypothesis (H₀):*  
  There is no difference in the mean PM2.5 levels between high-literacy and low-literacy states.  
  $$
  \mu_{\text{high}} = \mu_{\text{low}}
  $$

- *Alternative Hypothesis (H₁):*  
  There is a significant difference in the mean PM2.5 levels between the two groups.  
  $$
  \mu_{\text{high}} \ne \mu_{\text{low}}
  $$

---

###  Methodology

We use *Welch’s t-test*, which is appropriate for comparing the means of two independent groups when variances may not be equal.

*Key Steps:*

1. *Data Collection:*  
   - Gather literacy rates (2023–24) and PM2.5 concentration data for each state.
   - Split the states into high-literacy and low-literacy groups using the *median literacy rate* as the cutoff.

2. *Test Statistics:*
   - *t-statistic:* Quantifies the standardized difference between the group means.
   - *p-value:* Indicates the probability of observing such a difference if the null hypothesis were true.

3. *Significance Level:*  
   $$
   \alpha = 0.05
   $$

---

###  Results

| Group             | Mean PM2.5 (µg/m³) |
|-------------------|--------------------|
| High Literacy     | 38.55               |
| Low Literacy      | 54.55               |

- *t-statistic:* -1.75  
- *p-value:* 0.09  

*Interpretation:*  
Since the p-value (0.09) is greater than the significance level (0.05), we **fail to reject the null hypothesis**.  
Thus, there is **no statistically significant evidence** to conclude that PM2.5 levels differ between high-literacy and low-literacy states.

*Observed Trend (Not Statistically Significant):*
- States with higher literacy rates (e.g., Kerala, Goa, Himachal Pradesh) tend to show lower PM2.5 concentrations.
- States with lower literacy rates (e.g., Bihar, Uttar Pradesh, Jharkhand) tend to show higher PM2.5 concentrations.

However, this trend is **not strong enough** to be considered statistically significant based on the data.

---

###  Conclusion

Based on the available data, we do not find strong statistical evidence of a significant association between literacy levels and PM2.5 concentrations across Indian states.  
While states with higher literacy rates *tend* to show better air quality, the observed difference could be due to random chance rather than a true underlying relationship.

This suggests that while education may contribute to environmental awareness, **other factors** — such as industrialization, urbanization patterns, geographic conditions, and policy enforcement — could play a much larger role in determining air pollution levels.

Future studies with larger datasets or more controlled comparisons may help uncover more precise relationships between literacy and environmental quality.

---
"""

import numpy as np
import pandas as pd
import sklearn
from sklearn.cluster import KMeans

df=pd.read_excel("/content/drive/MyDrive/Literacy_Rate-Ministry_of_Finance_1.xls")
df

df.isnull().sum()

df_latest=pd.read_csv("/content/drive/MyDrive/literacy_rates_from_19_to_25.csv")
df_latest

df_latest.isnull().sum()

means=[]
for i in df.columns:
    if(type(i)==int):
        means.append(df[i].mean())

means

import matplotlib.pyplot as plt

for i in range(35):
    y = (df.iloc[i,1:]).astype(float)
    if(y.isna().any()==True):
        continue
    x = np.arange(len(y))
    plt.plot(x, y)
plt.show()

"""We observe that the linteracy rates in almost all the states increases linearly, thus we approximate the nan values with the corresponding value assuming the value of that state over years to follow a linear regression model."""

x = np.arange(len(means))
y = np.array(means)

m, c = np.polyfit(x, y, 1)
regression_line = m * x + c

plt.plot(x, y, label='Means', marker='o')

plt.plot(x, regression_line, label=f'Best-fit Line (y = {m:.2f}x + {c:.2f})', color='red', linestyle='--')

plt.xlabel('Index')
plt.ylabel('Value')
plt.title('Means with Best-fit Linear Regression')
plt.legend()
plt.grid(True)
plt.show()

df['inc(61-51)']=((df[1961]-df[1951]))
df['inc(71-61)']=((df[1971]-df[1961]))
df['inc(81-71)']=((df[1981]-df[1971]))
df['inc(91-81)']=((df[1991]-df[1981]))
df['inc(01-91)']=((df[2001]-df[1991]))
df['inc(11-01)']=((df[2011]-df[2001]))
# df

means_inc=[]
for i in df.columns:
    if(type(i)==str and "1" in i):
        means_inc.append(df[i].mean())

means_inc

year_cols = [1951, 1961, 1971, 1981, 1991, 2001]

dic = dict(zip(year_cols, means_inc))

for i in range(len(year_cols)-1,-1,-1):
    for j in range(len(df)):
        if(pd.isna(df.iloc[j,i+1])):
          df.iloc[j,i+1]=df.iloc[j,i+2]-(dic[year_cols[i]])

df.isnull().sum()

"""Preprocessed and successfully removed the nan values"""

df

df_sorted=df_sorted.drop(['inc(61-51)','inc(71-61)','inc(81-71)',	'inc(91-81)',	'inc(01-91)',	'inc(11-01)'], axis=1)

df_sorted

import pandas as pd
import plotly.graph_objects as go

# Extract and sort the year columns
years = [col for col in df.columns if str(col).isdigit()]
years = sorted(map(int, years))

# Sort the data for the initial year
init_year = years[0]
df_sorted = df.sort_values(by=init_year, ascending=True)

# Initialize figure
fig = go.Figure()

# Add initial bar chart
fig.add_trace(go.Bar(
    x=df_sorted[init_year],
    y=df_sorted["NAME_1"],
    orientation='h',
    marker_color='crimson',
    text=df_sorted[init_year],
    textposition='auto',
    name=str(init_year)
))

# Create frames for animation (each year)
frames = []
for year in years:
    df_sorted = df.sort_values(by=year, ascending=True)
    frames.append(go.Frame(
        data=[go.Bar(
            x=df_sorted[year],
            y=df_sorted["NAME_1"],
            orientation='h',
            marker_color='crimson',
            text=df_sorted[year],
            textposition='auto',
            name=str(year)
        )],
        name=str(year)
    ))

# Add frames and layout with slider
fig.frames = frames
fig.update_layout(
    title='Literacy Rates by Indian State',
    xaxis_title='Literacy Rate (%)',
    yaxis_title='State',
    yaxis=dict(tickfont=dict(size=10)),
    height=900,
    template='plotly_white',
    updatemenus=[dict(
        type='buttons',
        showactive=False,
        y=1.05,
        x=1.15,
        xanchor='right',
        yanchor='top',
        buttons=[dict(label='Play',
                      method='animate',
                      args=[None, dict(frame=dict(duration=1000, redraw=True), fromcurrent=True)])]
    )],
    sliders=[dict(
        active=0,
        y=0,
        x=0.1,
        len=0.9,
        xanchor="left",
        yanchor="bottom",
        pad={"b": 10},
        steps=[
            dict(method='animate',
                 args=[[str(year)], dict(mode='immediate', frame=dict(duration=1000), transition=dict(duration=300))],
                 label=str(year)) for year in years
        ]
    )]
)

fig.show()

"""Key Observations:

States with High Literacy Rates

Kerala leads with 96.2% literacy, driven by historical emphasis on education, grassroots campaigns like the Saksharata Pada Yatra, and universal access to schools.
Delhi (88.7%), Himachal Pradesh (86.6%), and Uttarakhand (87.6%) follow, benefiting from urbanization, governance, and inclusive policies like smart classrooms and vocational programs.

States with Significant Improvement

Mizoram: Improved from 31.14% in 1951 to 91.33% in 2011 due to community-driven initiatives and continuing education centers.
Tripura: Progressed from 20.24% in 1961 to 87.22% in 2011 through grassroots literacy drives and local government efforts.
Tamil Nadu: Rose from 26.52% in 1951 to 80.1% in 2011, largely due to the Mid-Day Meal Scheme, which improved school attendance and retention.

Important Schemes

Kerala's New India Literacy Programme focuses on marginalized groups like SC/ST communities and transgenders.
Himachal Pradesh's collaboration with the Sampark Foundation enhanced learning outcomes in primary education through technology-enabled teaching.
Delhi's Happiness Curriculum and smart classrooms have modernized education infrastructure, improving student engagement.

Overall Observations

Southern and northeastern states excel due to inclusive policies, community participation, and targeted programs, while northern states like Bihar show gradual progress despite socioeconomic challenges. Literacy improvements highlight the importance of sustained investments in education infrastructure and innovative teaching methods.


"""

df.columns

df.loc[25, 'NAME_1'] = 'Orissa'
df.loc[33, 'NAME_1'] = 'Uttaranchal'
df.loc[22, 'NAME_1'] = 'Meghalaya'
df.loc[0, 'NAME_1'] = 'Andaman and Nicobar'

import pandas as pd
import numpy as np
import plotly.graph_objs as go
from scipy.stats import gaussian_kde, norm, kstest
import matplotlib.cm as cm
import matplotlib.colors as mcolors

years = [1951, 1961, 1971, 1981, 1991, 2001, 2011]
metrics = []

vmin = df[years].min().min()
vmax = df[years].max().max()
color_norm = mcolors.Normalize(vmin=vmin, vmax=vmax)
cmap = cm.get_cmap('YlGn')

fig = go.Figure()
legend_shown = set()

for i, year in enumerate(years):
    valid_data = df[['NAME_1', year]].dropna()
    values = valid_data[year].values

    if len(values) == 0:
        continue

    kde = gaussian_kde(values)
    x_vals = np.linspace(min(values) - 5, max(values) + 5, 200)
    y_vals = kde(x_vals)
    mu, std = np.mean(values), np.std(values)
    y_gauss = norm.pdf(x_vals, mu, std)
    D_stat, p_val = kstest(values, 'norm', args=(mu, std))

    # Actual plot
    fig.add_trace(go.Scatter(
        x=x_vals, y=y_vals,
        mode='lines',
        name='KDE',
        line=dict(color='blue'),
        visible=(i == 0),
        legendgroup='kde',
        showlegend=('kde' not in legend_shown)
    ))
    legend_shown.add('kde')

    # Best fit Gaussian plot
    fig.add_trace(go.Scatter(
        x=x_vals, y=y_gauss,
        mode='lines',
        name='Best-fit Gaussian',
        line=dict(color='orange', dash='dot'),
        visible=(i == 0),
        legendgroup='gaussian',
        showlegend=('gaussian' not in legend_shown)
    ))
    legend_shown.add('gaussian')

    # State lines
    for j, (state, val) in enumerate(zip(valid_data['NAME_1'], valid_data[year])):
        rgba = cmap(color_norm(val))
        color = f"rgb({int(rgba[0]*255)}, {int(rgba[1]*255)}, {int(rgba[2]*255)})"

        fig.add_trace(go.Scatter(
            x=[val, val], y=[0, kde(val)],
            mode='lines+markers',
            name=state,
            marker=dict(color=color, size=6),
            line=dict(color=color, width=1),
            hoverinfo='text+x',
            hovertext=f"{state}: {val:.1f}%",
            visible=(i == 0),
            legendgroup=state,
            showlegend=True
        ))
        legend_shown.add(state)

# Slider
steps = []
for i, year in enumerate(years):
    traces_per_year = 2 + len(df)
    start_idx = i * traces_per_year
    end_idx = start_idx + traces_per_year
    visible = [False] * len(fig.data)

    for j in range(start_idx, min(end_idx, len(fig.data))):
        visible[j] = True

    valid_data = df[['NAME_1', year]].dropna()
    values = valid_data[year].values
    if len(values) > 0:
        mu, std = np.mean(values), np.std(values)
        D_stat, p_val = kstest(values, 'norm', args=(mu, std))
        title = f"Literacy Rate Distribution - {year}<br>Mean: {mu:.2f}, Std Dev: {std:.2f}, KS D: {D_stat:.4f}, p: {p_val:.4f}"
        metrics.append({
            "year": year,
            "mean": mu,
            "std": std,
            "ks_D": D_stat,
            "ks_p": p_val
                    })
    else:
        title = f"Literacy Rate Distribution - {year}<br>No data available"

    steps.append(dict(
        method="update",
        args=[{"visible": visible}, {"title": title}],
        label=year
    ))

# Final layout
fig.update_layout(
    sliders=[dict(
        active=0,
        currentvalue={"prefix": "Year: "},
        pad={"t": 50},
        steps=steps
    )],
    title=f"Literacy Rate Distribution - {years[0]}",
    xaxis_title="Literacy Rate (%)",
    yaxis_title="Density",
    template="plotly_white",
    height=700,
    legend=dict(
        title="Legend",
        orientation="v",
        yanchor="top",
        y=1,
        xanchor="left",
        x=1.02,
        font=dict(size=10),
        itemsizing='constant'
    )
)

fig.show()

metrics

"""### Hypothesis:

Literacy rates across Indian states in each census year follows a Gaussian (normal) distribution.

- **Null Hypothesis ($H_0$):** The literacy rate distribution in a given year follows a Gaussian distribution.  
- **Alternative Hypothesis ($H_1$):** The literacy rate distribution in a given year does not follow a Gaussian distribution.

### Methodology

To evaluate the hypothesis, we use the **Kolmogorov–Smirnov (K–S) test for normality**, which compares the empirical cumulative distribution function of the data with the cumulative distribution function of the reference (normal) distribution. The test yields:

- **D-statistic**: The maximum absolute difference between the two cumulative distribution functions.
- **p-value**: The probability of observing such a difference under the assumption that the data is normally distributed.

We adopt a significance level of $\alpha = 0.05$.

- If $p > \alpha$, we fail to reject $H_0$ (distribution is consistent with normality).
- If $p \leq \alpha$, we reject $H_0$ (distribution significantly deviates from normality).


### Results

| Year | Mean  | Std Dev | KS D   | p-value | Gaussian? |
|------|-------|---------|--------|---------|-----------|
| 1951 | 19.26 | 13.19   | 0.110  | 0.750   | Yes       |
| 1961 | 29.13 | 13.42   | 0.161  | 0.293   | Yes       |
| 1971 | 36.78 | 14.80   | 0.114  | 0.710   | Yes       |
| 1981 | 47.64 | 14.20   | 0.115  | 0.702   | Yes       |
| 1991 | 58.47 | 14.03   | 0.123  | 0.621   | Yes       |
| 2001 | 69.56 | 10.62   | 0.093  | 0.896   | Yes       |
| 2011 | 77.85 | 8.46    | 0.112  | 0.729   | Yes       |


### Justification

For all census years from 1951 to 2011, the K–S test yields p-values greater than the significance threshold ($\alpha = 0.05$). Therefore, we **fail to reject the null hypothesis** in each case.

This analysis provides statistical support for the proposition that the distribution of literacy rates across Indian states in each census year is consistent with a Gaussian distribution.

The distribution of literacy rates appears Gaussian due to the **Central Limit Theorem**, as literacy is influenced by many independent socio-economic factors. Over time, national policies and educational reforms have led to **gradual inter-state convergence**, reducing extreme disparities and resulting in a symmetric, bell-shaped distribution.
"""

pci=pd.read_csv("/content/cleaned_states_data.csv")
pci
population=pd.read_csv("/content/india_pop.csv")
population

import pandas as pd
import plotly.graph_objects as go

population.rename(columns={'States/Union': 'NAME_1'}, inplace=True)

years = [col for col in population.columns if str(col).isdigit()]
for year in years:
    population[year] = pd.to_numeric(population[year].astype(str).str.replace(',', ''), errors='coerce')
    population[year] = population[year].fillna(np.mean(population[year]))

init_year = sorted(map(int, years))[0]
df_sorted = population.sort_values(by=str(init_year), ascending=True)

# Initializing the figure
fig = go.Figure()

# initial bar chart
fig.add_trace(go.Bar(
    x=df_sorted[str(init_year)],
    y=df_sorted["NAME_1"],
    orientation='h',
    marker_color='crimson',
    text=df_sorted[str(init_year)],
    textposition='auto',
    name=str(init_year)
))

# Creating frames for animation
frames = []
for year in sorted(map(int, years)):
    year_str = str(year)
    df_sorted = population.sort_values(by=year_str, ascending=True)  # Ascending so right-to-left
    frames.append(go.Frame(
        data=[go.Bar(
            x=df_sorted[year_str],
            y=df_sorted["NAME_1"],
            orientation='h',
            marker_color='crimson',
            text=df_sorted[year_str],
            textposition='auto',
            name=year_str
        )],
        name=year_str
    ))

# Adding frames and animation layout
fig.frames = frames
fig.update_layout(
    title='Population by Indian State (1951–2011)',
    xaxis_title='Population (in thousands)',
    yaxis_title='State/UT',
    yaxis=dict(tickfont=dict(size=10)),
    height=900,
    template='plotly_white',
    updatemenus=[dict(
        type='buttons',
        showactive=False,
        y=1.05,
        x=1.15,
        xanchor='right',
        yanchor='top',
        buttons=[dict(label='Play',
                      method='animate',
                      args=[None, dict(frame=dict(duration=1000, redraw=True), fromcurrent=True)])]
    )],
    sliders=[dict(
        active=0,
        y=0,
        x=0.1,
        len=0.9,
        xanchor="left",
        yanchor="bottom",
        pad={"b": 10},
        steps=[
            dict(method='animate',
                 args=[[str(year)], dict(mode='immediate', frame=dict(duration=1000), transition=dict(duration=300))],
                 label=str(year)) for year in sorted(map(int, years))
        ]
    )]
)

fig.show()

"""Key Observations:

States like Uttar Pradesh and Bihar have high populations due to fertile Indo-Gangetic plains, abundant rivers, and agricultural sustainability, making them ideal for dense settlement. However, their population surge is also attributed to negligence in family planning, lower female literacy, and weaker healthcare outreach. In contrast, states like Maharashtra and Tamil Nadu have high populations driven by urbanization and economic growth. Rajasthan, despite its size, has a lower population due to desert terrain. Northern Himalayan states like Himachal Pradesh, Uttarakhand, Jammu & Kashmir, and Arunachal Pradesh remain sparsely populated due to harsh climate and rugged terrain. Smaller states and UTs like Goa, Sikkim, and Lakshadweep naturally house fewer people. Meanwhile, Kerala, Tamil Nadu, and Sikkim have curbed growth through strong family planning, female education, and healthcare initiatives
"""

import pandas as pd
import matplotlib.pyplot as plt


population_data=pd.read_csv("/content/drive/MyDrive/123.csv")
population_data['density'] = (
    population_data['density']
    .astype(str)
    .str.replace(',', '')
    .astype(float)
)

population_data['pm25'] = (
    population_data['pm 2.5']
    .astype(str)
    .str.replace(',', '')
    .astype(float)
)

population_data.dropna(subset=['density', 'pm25'], inplace=True)

density_threshold = population_data['density'].median()
population_data['Density_Group'] = population_data['density'].apply(
    lambda x: 'Low Density' if x < density_threshold else 'High Density'
)

import seaborn as sns
plt.figure(figsize=(8, 6))
sns.violinplot(data=population_data, x='Density_Group', y='pm25', palette='Set2')
plt.title('PM2.5 Distribution by Population Density Group')
plt.xlabel('Population Density Group')
plt.ylabel('PM2.5 (μg/m³)')
plt.grid(True)
plt.tight_layout()
plt.show()

from scipy.stats import norm
df_sorted = population_data.sort_values(by='density', ascending=False)
group_A = df_sorted.head(17)
group_B = df_sorted.tail(17)

mean_A, std_A = group_A['pm25'].mean(), group_A['pm25'].std()
mean_B, std_B = group_B['pm25'].mean(), group_B['pm25'].std()
n = len(group_A)

if std_A != 0 and std_B != 0:
        z = (mean_A - mean_B) / np.sqrt((std_A**2 + std_B**2) / n)
        p_value = 1 - norm.cdf(z)

        print(f"High Density PM2.5: {mean_A:.2f} ± {std_A:.2f}")
        print(f"Low Density PM2.5: {mean_B:.2f} ± {std_B:.2f}")
        print(f"Z-score: {z:.2f}")
        print(f"P-value: {p_value:.5f}")

        # Visualization
        critical_z = norm.ppf(0.95)
        x = np.linspace(-3, 8, 1000)
        plt.plot(x, norm.pdf(x), label='Null Distribution')
        plt.fill_between(x[x >= critical_z], norm.pdf(x[x >= critical_z]),
                         color='red', alpha=0.3, label='Critical Region (α=0.05)')
        plt.axvline(z, color='black', linestyle='--', label=f'Observed z = {z:.2f}')
        plt.xlabel('Z-Score')
        plt.ylabel('Density')
        plt.legend()
        plt.title('Z-Test: PM2.5 by Population Density')
        plt.show()

"""# Z-Test Analysis: PM₂.₅ and Population Density in Indian States

Calculations

**Grouping:**  
Top 17 and bottom 17 Indian states were ranked by population density.

---

**Means and Standard Deviations:**
- **High-density states:** Mean PM₂.₅ = 53.9 μg/m³, SD = 27.4  
- **Low-density states:** Mean PM₂.₅ = 34.4 μg/m³, SD = 13.9

---

**Statistical Test:** One-tailed *z*-test for difference in means:

$$
z = \frac{\bar{x}_{\text{high}} - \bar{x}_{\text{low}}}{\sqrt{\frac{s_{\text{high}}^2}{n} + \frac{s_{\text{low}}^2}{n}}}
$$

Where \( n = 17 \) for each group.

---

**Results:**
- \( z = 2.62 \)  
- \( p = 0.0044 \)  
- Critical \( z \)-value for \\( \alpha = 0.05 \\): 1.645

---

Interpretation

Since \( z = 2.62 > 1.645 \) and \( p = 0.0044 < 0.05 \), the difference in PM₂.₅ between high- and low-density states is **statistically significant**.  
High-density states have, on average, much higher PM₂.₅ pollution.

---

Conclusion

There is strong evidence that **higher population density is associated with increased PM₂.₅ pollution** in Indian states. This likely reflects more vehicles, industry, and construction in crowded areas, all of which contribute to poor air quality.

---

What Can Be Done?

- Expand **clean public transport** and reduce **vehicle emissions** in dense cities.  
- Enforce **stricter controls** on construction dust and industrial emissions in high-density zones.

"""

pci

import pandas as pd
import plotly.graph_objects as go

year_cols = [col for col in pci.columns if col.replace('-', '').replace('/', '').isdigit()]
years = sorted(year_cols, key=lambda x: int(x[:4]))  # Sorted by start year

# Initializing the figure
init_year = years[0]
df_sorted = pci.sort_values(by=init_year, ascending=True)

fig = go.Figure()

# Initial bar chart
fig.add_trace(go.Bar(
    x=df_sorted[init_year],
    y=df_sorted["State/UT"],
    orientation='h',
    marker_color='crimson',
    text=df_sorted[init_year],
    textposition='auto',
    name=init_year
))

# Frames for animation
frames = []
for year in years:
    df_sorted = pci.sort_values(by=year, ascending=True)
    frames.append(go.Frame(
        data=[
            go.Bar(
                x=df_sorted[year],
                y=df_sorted["State/UT"],
                orientation='h',
                marker_color='crimson',
                text=df_sorted[year],
                textposition='auto',
                name=year
            )
        ],
        name=year
    ))

# slider and animation controls
fig.frames = frames
fig.update_layout(
    title='PerCapita Income wrt average (in %)',
    xaxis_title='PerCapita Income (in %)',
    yaxis_title='State / UT',
    height=1000,
    template='plotly_white',
    updatemenus=[dict(
        type='buttons',
        showactive=False,
        y=1.05,
        x=1.15,
        xanchor='right',
        yanchor='top',
        buttons=[dict(label='Play',
                      method='animate',
                      args=[None, dict(frame=dict(duration=1000, redraw=True), fromcurrent=True)])]
    )],
    sliders=[dict(
        active=0,
        y=0,
        x=0.1,
        len=0.9,
        xanchor="left",
        yanchor="bottom",
        pad={"b": 10},
        steps=[dict(method='animate',
                    args=[[year], dict(mode='immediate', frame=dict(duration=1000), transition=dict(duration=300))],
                    label=year) for year in years]
    )]
)

fig.show()

"""Key Observations:

The animated visualization of rising per capita income across Indian states reveals clear disparities in economic growth. States like Delhi, Goa, and Sikkim consistently rank at the top, benefiting from a strong service sector base, high urbanization, better infrastructure, and a skilled workforce driven by higher literacy. Southern states—notably Tamil Nadu, Karnataka, and Kerala—show a steady upward trend, largely attributed to sustained investments in education, healthcare, and industrial development since the 1990s economic liberalization, which opened doors to private and foreign investment. This period also marked the IT revolution, with states like Karnataka and Tamil Nadu emerging as major tech hubs, significantly boosting their economies. In contrast, Bihar, Uttar Pradesh, and Madhya Pradesh rarely feature among the top performers, reflecting slower economic progress due to high population burdens, limited industrialization, agricultural dependence, and weaker infrastructure and educational systems. The widening income gap underscores that economic growth in India remains geographically uneven, highlighting an urgent need for targeted policies that strengthen education, healthcare, and industrial capacity in lagging states to ensure more inclusive development.

"""

df_pci_sorted = pci.sort_values(by="State/UT").reset_index(drop=True)
df_literacy_sorted = df.sort_values(by='NAME_1').reset_index(drop=True)
df_population_sorted = population.sort_values(by='States/Union').reset_index(drop=True)

df_population_sorted

# Already done:
states_pci = set(df_pci_sorted['State/UT'].unique())
states_literacy = set(df_literacy_sorted['NAME_1'].unique())
states_population = set(df_population_sorted['States/Union'].unique())

all_states = states_pci | states_literacy | states_population
common_states = states_pci & states_literacy & states_population

inconsistent_states = all_states - common_states

print("States not present in all 3 DataFrames:")
print(inconsistent_states)

df_pci_sorted = df_pci_sorted[df_pci_sorted['State/UT'].isin(common_states)].reset_index(drop=True)
df_literacy_sorted = df_literacy_sorted[df_literacy_sorted['NAME_1'].isin(common_states)].reset_index(drop=True)
df_population_sorted = df_population_sorted[df_population_sorted['States/Union'].isin(common_states)].reset_index(drop=True)

import pandas as pd
import plotly.express as px
years=[1961, 1971, 1981, 1991, 2001, 2011]

df_list = []
for i in range(len(df_literacy_sorted)):
    for year in years:
        population_str = df_population_sorted.loc[i, str(year)].replace(',', '').replace(' ', '')
        df_list.append({
            'State': df_literacy_sorted.loc[i, 'NAME_1'],
            'Year': year,
            'LiteracyRate': df_literacy_sorted.loc[i, year],
            'Population': int(population_str),
            'Percapita Income': df_pci_sorted.loc[i, f'{year-1 if year > 1960 else year}-{str(year)[-2:]}']  # Format year for PCI column
        })

df = pd.DataFrame(df_list)

# Create the bubble chart
fig = px.scatter(
    df,
    x="Percapita Income",
    y="LiteracyRate",
    animation_frame="Year",
    animation_group="State",
    size="Population",
    color="State",
    hover_name="State",
    size_max=60,
    range_x=[30, 80],
    range_y=[40, 100],
    labels={"Percapita Income": "Percapita Income wrt average (%)", "LiteracyRate": "Literacy Rate (%)"}
)

fig.update_layout(title="Employment vs Literacy Bubble Plot by Year", title_x=0.5)
fig.show()

df

# Mapping of states to regions
region_map = {
    # North India
    'Delhi': 'North',
    'Haryana': 'North',
    'Punjab': 'North',
    'Himachal Pradesh': 'North',
    'Uttar Pradesh': 'North',
    'Chandigarh': 'North',

    # South India
    'Andhra Pradesh': 'South',
    'Tamil Nadu': 'South',
    'Kerala': 'South',
    'Karnataka': 'South',
    'Telangana': 'South',
    'Puducherry': 'South',

    # East India
    'Bihar': 'East',
    'Jharkhand': 'East',
    'Odisha': 'East',
    'West Bengal': 'East',

    # West India
    'Rajasthan': 'West',
    'Gujarat': 'West',
    'Maharashtra': 'West',
    'Goa': 'West',

    # Central India
    'Madhya Pradesh': 'Central',
    'Chhattisgarh': 'Central',

    # Northeast India
    'Assam': 'Northeast',
    'Meghalaya': 'Northeast',
    'Manipur': 'Northeast',
    'Mizoram': 'Northeast',
    'Nagaland': 'Northeast',
    'Tripura': 'Northeast',
    'Sikkim': 'Northeast',
    'Arunachal Pradesh': 'Northeast',
}

df['Region'] = df['State'].map(region_map)

df.columns

df

df1=df[df['Year']==2011]
corr_matrix = df_1[['LiteracyRate', 'Population', 'Percapita Income']].corr()

# Correlation matrix
print("Correlation Coefficients:")
print(corr_matrix.round(2))

"""Hypothesis: Literacy isn’t just about reading—it’s a gateway to opportunities. It enhances an individual's ability to contribute productively to the economy, and when scaled across a population, this contributes to higher per capita income for the region.



Null Hypothesis (H₀):
There is no correlation between literacy rate and per capita income.
(i.e., ρ = 0)

Alternative Hypothesis (H₁):
There is a positive correlation between literacy rate and per capita income.
(i.e., ρ > 0)

Results:

### Correlation Matrix

|                      | Literacy Rate | Population | Per Capita Income |
|----------------------|---------------|------------|-------------------|
| **Literacy Rate**    | 1.00          | -0.44      | 0.61              |
| **Population**       | -0.44         | 1.00       | -0.37             |
| **Per Capita Income**| 0.61          | -0.37      | 1.00              |

Justification:

The correlation coefficient between literacy rate and per capita income is 0.61, indicating a moderately strong positive linear relationship. In socioeconomic contexts, a correlation above 0.5 is statistically significant and suggests a meaningful trend.

This trend is theoretically supported:

   1) Access to Better Jobs: Literate individuals can access formal-sector employment and skilled roles, which offer better compensation.

2) Higher Education Pathways: Literacy enables further education and upskilling, leading to better career progression and income potential.

3) Improved Productivity: Literate workers are more efficient, can adapt to technology leading to higher individual output.

4) Entrepreneurship and Innovation: Literacy empowers people participate in economic growth.

Real-world instances:

1) Kerala, known for its high literacy rate, consistently ranks high in per capita income.

2) Bihar, with lower literacy levels, shows significantly lower income levels.

This relationship aligns with economic theory and practical development models that recognize education as a key lever for poverty reduction and prosperity.

Conclusion:

Given the significant positive correlation between literacy rate and per capita income, and supported by both statistical analysis and real-world observations, we reject the null hypothesis. The data provides evidence that higher literacy rates are associated with greater economic prosperity, making literacy not just a human right but a catalyst for regional development.

Hypothesis: Higher population does not always lead to higher per capita income. In fact, larger populations can strain resources, infrastructure, and employment opportunities, potentially suppressing income levels on a per-person basis.

Null Hypothesis (H₀₂):
There is no correlation between population size and per capita income (ρ = 0).

Alternative Hypothesis (H₁₂):
There is a negative correlation between population size and per capita income (ρ < 0).

Results:

### Correlation Matrix

|                      | Literacy Rate | Population | Per Capita Income |
|----------------------|---------------|------------|-------------------|
| **Literacy Rate**    | 1.00          | -0.44      | 0.61              |
| **Population**       | -0.44         | 1.00       | -0.37             |
| **Per Capita Income**| 0.61          | -0.37      | 1.00              |

Justification:

Population vs. Per Capita Income (r = -0.37):

This negative correlation indicates that, in general, states with larger populations tend to have lower per capita income. This could be due to:

1) Resource Dilution: More people competing for limited jobs, education, healthcare, and infrastructure.

2) Lower Human Development Indices: Highly populated states often face challenges in education, healthcare, and economic distribution.

3) Urban-Rural Divide: Larger populations may include vast rural regions with lower economic output.

Real-world instances:

1) Uttar Pradesh, with one of the largest populations, consistently ranks low in per capita income.

2) Smaller states like Goa or Kerala tend to have more balanced population sizes and higher income levels.

Conclusion:

We reject the null hypothesis (H₀₂) for population and income in favor of the alternative: Higher population correlates with lower per capita income, likely due to resource and opportunity constraints.
"""

df

import pandas as pd
import folium

df_2011 = df[df["Year"] == 2011]

m = folium.Map(location=[22.5, 80], zoom_start=5)

folium.Choropleth(
    geo_data=india_geo,
    name="choropleth",
    data=df_2011,
    columns=["State", "LiteracyRate"],
    key_on="feature.properties.NAME_1",
    fill_color="YlGn",
    fill_opacity=0.7,
    line_opacity=0.2,
    legend_name="Literacy Rate (%) - 2011",
).add_to(m)

folium.LayerControl().add_to(m)

m

import pandas as pd
import folium

df_2011 = df[df["Year"] == 2011]

m = folium.Map(location=[22.5, 80], zoom_start=5)

folium.Choropleth(
    geo_data=india_geo,
    name="choropleth",
    data=df_2011,
    columns=["State", "Percapita Income"],
    key_on="feature.properties.NAME_1",
    fill_color="YlGn",
    fill_opacity=0.7,
    line_opacity=0.2,
    legend_name="Percapita Income (%) wrt mean Percapita Income - 2011",
).add_to(m)

folium.LayerControl().add_to(m)

m

import pandas as pd
import folium

df_2011 = df[df["Year"] == 2011]

m = folium.Map(location=[22.5, 80], zoom_start=5)

folium.Choropleth(
    geo_data=india_geo,
    name="choropleth",
    data=df_2011,
    columns=["State", "Population"],
    key_on="feature.properties.NAME_1",
    fill_color="YlGn",
    fill_opacity=0.7,
    line_opacity=0.2,
    legend_name="Population - 2011",
).add_to(m)

# 5. Add layer control
folium.LayerControl().add_to(m)

# 6. Display map
m

df

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import plotly.graph_objects as go
import plotly.express as px
from collections import defaultdict
from sklearn.metrics import silhouette_score

colors = px.colors.qualitative.Set1
cluster_map = defaultdict(lambda: defaultdict(list))
frames = []
fig = go.Figure()

years = sorted(df["Year"].unique())

silhouette_by_year = {}

for year in years:
    data_year = df[df["Year"] == year].dropna(subset=["LiteracyRate"])
    states = data_year["State"].values
    literacy_rates = data_year["LiteracyRate"].values.reshape(-1, 1)

    kmeans = KMeans(n_clusters=5, random_state=0, n_init=10)
    labels = kmeans.fit_predict(literacy_rates)

    # Silhouette Score
    if len(np.unique(labels)) > 1:
        sil_score = silhouette_score(literacy_rates, labels)
    silhouette_by_year[year] = sil_score

    # cluster mapping
    for i in range(5):
        cluster_states = [state for state, label in zip(states, labels) if label == i]
        cluster_map[year][i] = cluster_states

    scatter = go.Scatter(
        x=labels,
        y=literacy_rates.flatten(),
        mode='markers+text',
        text=states,
        textposition='top center',
        marker=dict(size=12, color=[colors[l] for l in labels], line=dict(width=1, color='black')),
        hovertemplate='<b>%{text}</b><br>Cluster: %{x}<br>Literacy: %{y:.2f}%<extra></extra>',
        showlegend=False
    )

    frames.append(go.Frame(data=[scatter], name=str(year)))

# Initial plot setup
init_data = df[df["Year"] == years[0]].dropna(subset=["LiteracyRate"])
init_states = init_data["State"].values
init_lit = init_data["LiteracyRate"].values.reshape(-1, 1)
init_labels = KMeans(n_clusters=5, random_state=0, n_init=10).fit_predict(init_lit)

fig.add_trace(go.Scatter(
    x=init_labels,
    y=init_lit.flatten(),
    mode='markers+text',
    text=init_states,
    textposition='top center',
    marker=dict(size=12, color=[colors[l] for l in init_labels], line=dict(width=1, color='black')),
    hovertemplate='<b>%{text}</b><br>Cluster: %{x}<br>Literacy: %{y:.2f}%<extra></extra>',
    showlegend=False
))

# Final layout with slider and play/pause
fig.update_layout(
    title="Literacy Rate Clustering (k=5) — Labeled States (1961–2011)",
    xaxis_title="Cluster",
    yaxis_title="Literacy Rate (%)",
    xaxis=dict(tickmode='array', tickvals=[0, 1, 2, 3, 4], range=[-0.5, 4.5]),
    yaxis=dict(range=[0, df["LiteracyRate"].max() + 10]),
    updatemenus=[dict(
        type="buttons",
        showactive=False,
        y=1.15,
        x=1.05,
        xanchor="right",
        yanchor="top",
        buttons=[
            dict(label="▶ Play", method="animate",
                 args=[None, {"frame": {"duration": 1000, "redraw": True}, "fromcurrent": True}]),
            dict(label="⏸ Pause", method="animate",
                 args=[[None], {"frame": {"duration": 0, "redraw": False}, "mode": "immediate"}])
        ]
    )],
    sliders=[{
        "steps": [{"method": "animate",
                   "args": [[str(y)], {"mode": "immediate", "frame": {"duration": 1000, "redraw": True}}], "label": str(y)} for y in years],
        "transition": {"duration": 300},
        "x": 0.1,
        "y": -0.1,
        "currentvalue": {"prefix": "Year: "},
        "len": 0.9
    }]
)

fig.frames = frames
fig.show()

# Display cluster mappings
print("Clustered States by Year and Cluster:")
for year in cluster_map:
    print(f"\nYear: {year}")
    for cluster in sorted(cluster_map[year]):
        print(f"  --> Cluster {cluster}: {cluster_map[year][cluster]}")

print("\nSilhouette Scores by Year:")
for year, score in silhouette_by_year.items():
    print(f"Year {year}: Silhouette Score = {score:.3f}")

"""Hypothesis

The literacy rates of Indian states, when grouped using clustering methods like KMeans, show consistent patterns over time. Some states stay in the top-performing groups, while others remain in the lower-performing groups. A few states move upward, showing improvement over the years.

Null Hypothesis

There are no significant patterns in the clustering of Indian states based on literacy rates, and any observed changes are due to chance.

Alternative Hypothesis

There are consistent and meaningful patterns in the clustering of Indian states based on literacy rates. Some states stay in top clusters, others stay in lower ones, and a few improve over time.

Justification:

The clustering of Indian states based on literacy rates over the decades from 1961 to 2011 reveals distinct and persistent patterns, supporting the alternative hypothesis. The silhouette scores for each decade — ranging from 0.555 in 1981 to a high of 0.706 in 1961 — consistently exceed the commonly accepted threshold of 0.5. This indicates that the clusters formed through KMeans are well-separated and meaningful.


Further reinforcing the hypothesis is the consistency observed in cluster memberships over time. Certain states like Kerala and Delhi repeatedly appear in the highest-performing clusters. Kerala, in particular, remains consistently isolated in the top cluster or with very few other states, highlighting its long-standing emphasis on education and literacy. On the opposite end of the spectrum, states such as Bihar, Uttar Pradesh, Madhya Pradesh, Rajasthan, and Jharkhand are frequently grouped in the lowest clusters across all decades. This persistence suggests deep-rooted educational challenges that are not quickly or easily overcomeable.

Additionally, some states display upward mobility in the cluster hierarchy, demonstrating gradual improvement. For example, Tamil Nadu, Himachal Pradesh, Maharashtra, and Tripura show transitions into better-performing clusters over time. These shifts may be attributed to sustained policy interventions, increased investment in education, and improved governance. Moreover, smaller union territories and urbanized states like Chandigarh and Puducherry also consistently rank higher, likely due to better infrastructure, governance, and access to resources.



In conclusion,

The observed clustering patterns are not artifacts of random variation. Rather, they represent consistent and interpretable groupings of states based on their literacy performance. The stability of these clusters over time, supported by solid silhouette scores and clear sociopolitical explanations, leads us to reject the null hypothesis. The consistent clustering patterns over time support the alternative hypothesis — literacy rate trends are not random.
Key takeaways include:

Regional disparities in literacy, highlighting the need for targeted policy support.

High-performing states (like Kerala and Delhi) are always at the top with high literacy, due to sustained investment in education.

Improving states (like Tamil Nadu) demonstrate that progress is possible with focused strategies.

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
"""

df = pd.read_excel("/content/2011-IndiaState-0000.xlsx")

df_total = df[df['TRU'] == 'Total'].reset_index(drop=True)

df_total['Literacy Rate'] = ((df_total['M_LIT'] + df_total['F_LIT']) / df_total['TOT_P']) * 100

fertility_rates = [2.4, 2.3, 1.9, 1.9, 1.8, 2.3, 2.3, 1.8, 3.0, 3.3, 3.7, 1.2, 2.1, 2.2, 2.6, 2.2, 1.7, 3.0, 2.3, 1.6, 2.9, 2.2, 2.8, 2.9, 2.3, 1.5, 2.5, 1.8, 1.8, 1.9, 1.7, 1.4, 1.8, 1.7, 1.7, 1.8]

# Adding column fertility_rates
df_total["Fertility Rate"] = fertility_rates[:len(df_total)]

fig = px.scatter(
    df_total,
    x="Literacy Rate",
    y="Fertility Rate",
    size="TOT_P",
    color="Name",
    hover_name="Name",
    size_max=50,
    labels={"TOT_P": "Total Population"},
    title="Fertility Rate vs Literacy Rate (TRU = Total)"
)

fig.update_traces(marker=dict(
    line=dict(width=1, color='black'),
    opacity=0.8
))

fig.update_layout(
    width=1100,
    height=700,
    legend_title="State/UT",
    xaxis_title="Literacy Rate (%)",
    yaxis_title="Fertility Rate",
    hovermode="closest"
)

fig.show()

import matplotlib.pyplot as plt

plt.scatter(df_total['Literacy Rate'], df_total['Fertility Rate'])
plt.xlabel('Literacy Rate')
plt.ylabel('Fertility Rate')
plt.title('Literacy Rate vs. Fertility Rate')
plt.show()

# The correlation coefficient
correlation = df_total['Literacy Rate'].corr(df_total['Fertility Rate'])
print(f"Pearson correlation coefficient: {correlation}")

"""Hypothesis:

Null Hypothesis (H₀):
There is no association between literacy rate and broader development indicators like fertility rate.
Alternative Hypothesis (H₁):
There is a significant association between literacy rate and development indicators. States with higher literacy tend to exhibit lower fertility rates, higher per capita income, and better health and gender equity outcomes. (i.e., ρ ≠ 0)

Results

Pearson Correlation

Literacy Rate vs Fertility Rate: ρ  = -0.774

This indicates a strong negative linear correlation—as literacy increases, fertility decreases significantly. Here ρ the correlation metric between literacy and fertility is negative and very far from 0 and near to -1 indicating the fertility rate is indeed inversely proportional .


 Justification

Literate populations are better informed about contraception, family planning, and the health benefits of delaying childbirth. Female education especially leads to later marriages and fewer children, empowering women to make informed reproductive choices. This awareness reduces fertility rates and improves maternal and child health outcomes, contributing to overall socio-economic development.




 Key Observations

1. Literacy and Fertility Rate: Strong Inverse Relationship
Kerala: Literacy rose from 70% (1980s) to 94% (2011), while fertility dropped from 3.5 to 1.5. This was driven by widespread female literacy, effective healthcare, and awareness campaigns like JSY, Mission Arogya Keralam, and community-led programs (ASHA, Kudumbashree).
Bihar: Despite efforts through schemes like JSY and ASHA outreach, fertility remains high (3.5) due to low female literacy, early marriages, and limited awareness, which weaken the impact of these initiatives.

"""